<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Chris Forster: A Walk Through the Metadata: Gender in the HathiTrust Dataset
</title>
    <meta charset="UTF-8">

    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" type="text/css" href="/css/pygments.css" />
    <link rel="stylesheet" type="text/css" href="/css/style.css" />
    <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="cforster.com Atom feed" />
  </head>
  <body>

    <article class="post">
      <div class="frontmatter">
	<h1 class="title"><p>A Walk Through the Metadata: Gender in the HathiTrust Dataset</p>
</h1>

	<time class="timestamp" datetime="2015-09-08" >Sep 08, 2015</time>
      </div>

      <div class="post-content">
	<p>[This post, featuring too many graphs, was created with <a href="http://yihui.name/knitr/"><code>knitr</code></a>. You can see the source that generated those graphs, and the rest of the post, <a href="http://cforster.com/files/2015-09-08-gender-in-hathitrust-dataset.Rmd">here</a>. <span class="addition"><strong>Update</strong>: Many thanks to <a href="https://twitter.com/lincolnmullen">Lincoln Mullen</a> who is not only the maintainer, and one of the authors of the <code>gender</code> package, but noted that I was (inaccurately) using publication dates, rather than author birthdates, when inferring the gender of names; he suggested a smart way of approximating author birth dates (used below), and also drew my attention to the <code>napp</code> dataset, accessible by the <code>gender</code> package. In light of his comments I made a few changes, re-ran the data, and have updated this post. The plots are new; I’ve added a little new text as well which, like this, is in dark blue. <strong>9/11/15</strong></span>]</p>
<div class="epigraph">
<p>“there is no such thing as distinguishing men from women.”<br />—<a href="https://books.google.com/books?id=o4ZHAAAAYAAJ&lpg=PA478&ots=rSPKars5gB&dq=%22there%20is%20no%20such%20thing%20as%20distinguishing%20men%20from%20women%22&pg=PA478#v=onepage&q&f=false"><em>The Critical Review</em>, 1777</a></p>
</div>
<p>I’ve been tinkering with the HathiTrust dataset that Ted Underwood and HathiTrust released last month.<span class="marginnote">Some Links: [<a href="https://sharc.hathitrust.org/genre">The Dataset</a>]; [<a href="http://tedunderwood.com/2015/08/07/a-dataset-for-distant-reading-literature-in-english-1700-1922/">Ted Underwood’s Discussion of It</a>]; [<a href="http://cforster.com/2015/08/exploring-hathitrust-dataset">My Previous Exploration of It, Mostly Using R</a>]</span> The thorniest questions I’ve encountered concern how to handle/understand volumes and titles which occur in the dataset more than once (and some related issues—multivolume works, etc). I’ll try to write a quick post about those issues in the future. For now, let’s look at other ways we might explore this dataset.</p>
<h2 id="examining-the-gender-of-authorship-in-hathitrust-summary-metadata">Examining the Gender of Authorship in HathiTrust Summary Metadata</h2>
<p>I find the metadata fascinating in a way that the actual <em>data</em> (the word frequencies for each volume) is not. Let’s consider, for example, the relationship between authorship in the dataset and gender. Authorial gender is not one of the included metadata fields, but we might try to examine it by using the <a href="https://github.com/ropensci/gender"><code>gender</code></a> package for <code>R</code>. This package uses a variety of historical sources (Social Security data, US Census data, as well as some other sources) to intelligently infer gender based on first names <span class="strikethrough">(since the package relies on largely US data, it might not be as successful in predicting gender of names in other Anglophone countries, including England—an issue I note here, parenthetically, and then ignore)</span>. <span class="addition">The package can also use <code>napp</code> data, covering Canada, the United Kingdom, Germany, Iceland, Norway, and Sweden, from the years 1758 to 1910</span>.<span class="marginnote">This <a href="http://apps.lincolnmullen.com/gender-predictor/">web app</a> nicely illustrates what the package does.</span> Here, for instance, is how you would load the package and infer the likely gender of the name a <em>George</em> born in 1819:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gender)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">gender</span>(<span class="st">&#39;george&#39;</span>,<span class="at">method=</span><span class="st">&#39;napp&#39;</span>,<span class="at">year=</span><span class="dv">1819</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>Source<span class="sc">:</span> local data frame [<span class="dv">1</span> x <span class="dv">6</span>]</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    name proportion_male proportion_female gender year_min year_max</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> george               <span class="dv">1</span>                 <span class="dv">0</span>   male     <span class="dv">1819</span>     <span class="dv">1819</span></span></code></pre></div>
<p>This sort of inference based on first names is obviously imperfect; there are cases where, for a variety of reasons, the prediction will be wrong. The suggestion that in 1819 the name <em>George</em> belongs to a man may be very wrong indeed if that particular George is the author of <em>Middlemarch</em>. For certain purposes, however, that misattribution may be exactly what we’re interested in. The simplicity of the approach can be a strength. The package, in most cases, will make the same inference—even the same incorrect inference—about the gender of a name as a reader would. This makes it ideal if you’re interested in how readers understood the authorship of the books they were reading, or how (perceived) authorial gender shaped the market for literature.<span class="marginnote">Before we start taking this too seriously, Francis Beaumont’s name is detected as female (understandable, but wrong); as is Oliver Goldsmith’s (?!?!) in some years (e.g. 1792).</span></p>
<p>Such a summary of the dataset is very different than, say, using the gender information inferred about a volume based on its author’s first name to train a classifier on the volume-level word counts. Such a classifier could be used on texts from outside the dataset, or on texts <em>within</em> the dataset where an author’s gender is unknown. One might try to use it to test Virginia Woolf’s “guess that Anon, who wrote so many poems without signing them, was often a woman” (49). <em>That</em> sort of project, however, which would attempt to link “gender” (and in this case what exactly that word means becomes rather pressing) not simply to a name in a metadata field, but to a vocabulary (or some other representation of language use), would begin to encounter the thornier theoretical/methodological questions that I am so happy to skirt past here.</p>
<p>Hewing to this more modest, and (I think) less theoretically fraught, goal of understanding the makeup of the dataset, I used the <code>gender</code> package to infer the gender of the author of each volume in the three HathiTrust datasets. <span class="addition">To maximize recognition I used a somewhat heterdox method. Since the package expects birthdates, I subtracted 30 and 50 years from the publication date and passed this range to the package (this was Lincoln’s, I think very reasonable, suggestion). I queried against first the <code>napp</code> data; if this returned no result I tried the <code>ipums</code> census data. In both cases, I massaged the dates so that if they were out of range, I checked against the earliest available date (a historically imprecise result strikes me as better than no result at all).</span> So to every row in the metadata summary files I added a column for gender, which represented the result of applying this idiosyncratic use of the <code>gender</code> function to the author’s first name.<span class="marginnote">For my purposes a “first name” is the first word after the comma in the <code>author</code> field; there would be better ways to do this.</span> (This process was actually rather time consuming—<em>hint</em>, <code>mclapply</code> is your friend, as are virtualized servers you can let hum away for hours. <span class="addition">Lincoln notes that the package allows you to pass a vector of names to the package; this makes the process more efficient for large datasets, paritcularly when names are repeated. I nevertheless did it the (seriously) less efficient way, in part because I had written the code for an earlier version of the <code>gender</code> package, and in part because my odd use of <em>two</em> methods to try to find data complicates matters.</span>)</p>
<p>I then tallied up the number of works by men and women for each genre. (I did the tallying with Python; you can find the results of those tallies as CSVs <a href="https://gist.github.com/c-forster/2acc9f84a7ecc8375715">here</a>.) In addition to <code>male</code> and <code>female</code>, there are two other categories here: <code>missing</code> means a name was not provided (or, more precisely, was not detected by my script) in the HathiTrust metadata; <code>undetected</code> means that the <code>gender</code> package had not value for the “name” it was given (or, more precisely, whatever string it received from how I parsed the name). That is, <code>missing</code> means <em>no name</em> and <code>undetected</code> means that <code>gender</code> had no association for the name. (There are also columns for each of these values normalized by the number of volumes in the dataset for that year). Without further ado, three area graphs representing the gender breakdown of authorship in each of the HathiTrust datasets (fiction, poetry, drama).</p>
<p><span class="marginnote">If you right click and open each graph in another tab, they should be a bit bigger.</span></p>
<p><img src="/../figs/2015-08-27-gender-in-hathitrust-dataset/gender-area%20graphs-1.png" alt="center" /> <img src="/../figs/2015-08-27-gender-in-hathitrust-dataset/gender-area%20graphs-2.png" alt="center" /> <img src="/../figs/2015-08-27-gender-in-hathitrust-dataset/gender-area%20graphs-3.png" alt="center" /></p>
<p>The data before 1800 is sparse and so these graphs look a little volatile. The prevalence of <code>missing</code> and <code>undetected</code> in the fiction data before 1800, however, may reflect the lack of attribution common in the late eighteenth century. “Over 80 per cent of all novel titles published in the 1770s and 1780s were published anonymously,” James Raven claims in the introduction to the first volume of the two volume <em>The English Novel 1770–1829: A Bibliographical Survey of Prose Fiction Published in the British Isles</em> (41). (I’ll abbreviate that <em>BSPF</em> for the rest of the post).</p>
<p><span class="addition"><a href="https://twitter.com/heatherfro/status/641710059748204544">In a tweet</a>, <a href="https://twitter.com/heatherfro">Heather Froelich</a> asks, “What’s in those slices of undetected and missing texts.” Looking at the amended metadata file, it looks that there are ~11,000 records with either <code>missing</code> or <code>undetected</code> gender (that’s ~10% of the dataset). The most frequently occuring titles in the <code>missing</code> data are:</span></p>
<pre><code>The New British novelist;
The British novelists,
Stories by American authors,
The Harvard classics shelf of fiction,
The German classics of the nineteenth and twentieth centuries,
The International library of famous literature,
The lady of the manor,
The book of the thousand nights and one night,
The book of the thousand nights and a night,
The thousand and one nights,
The Odyssey of Homer,
Stories by English authors,
The Bibliophile library of literature, art and rare manuscripts,
The masterpiece library of short stories,
Florence Macarthy,</code></pre>
<p><span class="addition">So why is the author missing from these? Checking the full records, the most frequenltly occuring items in this series are multivolume collections of other works. <em>The New British Novelists</em> lists no author in the dataset’s <code>author</code> metadata; the title appears in the fiction dataset 50 times. Checking <a href="http://catalog.hathitrust.org/Record/008558481">the original page images</a>, we see that this is a series, published starting in 1820 which collects different novels by major British novelists. It includes a range of major novels, many themselves multivolume works: <em>Clarissa</em>, <em>Robinson Crusoe</em>, <em>Humphrey Clinker</em>, and so on. <a href="http://catalog.hathitrust.org/Record/007688604"><em>The Harvard Classics Shelf of Fiction</em></a> appears to be a similar case. <span class="marginnote">Is there an existing literature on these sorts of collections and their role in reputation creation/maintenance?</span> In the earlier period, there are titles (like <a href="http://catalog.hathitrust.org/Record/007700038"><em>The Infernal Wanderer</em></a>) which simply lack an author; others (like <a href="http://catalog.hathitrust.org/Record/008405386"><em>Turkish Tales</em></a>) lack an author in the dataset, but currently have one in HathiTrust (perhaps because this record has been updated since the dataset was exported); and quite a few don’t meet my naming convention. Works by <a href="http://catalog.hathitrust.org/Record/001227706">Phalaris</a>, [Madame d’] <a href="http://catalog.hathitrust.org/Record">Aulnoy</a>, [Mssr.] <a href="http://catalog.hathitrust.org/Record/100024486">Scarron</a>, [Mrs.] <a href="http://catalog.hathitrust.org/Record/000245324">Manley</a>, Volatire, Virgil, and many others are “missing” because when I try to splice ’em up (relying on a comma to separate first and last names), we get nothing. Some of these authors were referred to simply by a last name and title (Mrs. Manley) and this has entered the dataset as simply <code>Manley</code>.</span></p>
<p><span class="addition">In the <code>undetected</code> data; the most frequently occuring names are:</span></p>
<pre><code>Bjørnson, Bjørnstjerne
Dostoyevsky, Fyodor
Orczy, Emmuska Orczy
Burgess, Gelett
Cullum, Ridgwell
Hearn, Lafcadio
Watanna, Onoto
MacManus, Seumas
Tagore, Rabindranath
Hemyng, Bracebridge
Gordon-Cumming, Roualeyn
Ritchie, Leitch</code></pre>
<p><span class="addition">A look at the names is enough to guess why <code>gender</code> likely had a probably with them. (There are sufficiently few names here (321 unique individual, undetected names) that I am half tempted to put together a manual reconillation for names and genders). It also provides a clear illustration of the implicit cultural construction of “data.” These “undetected” names are largely non-Anglophone names—and so the attempt to infer one culturally mediated category (<em>gender</em>) gets complicated by the complexities of another one (nationality). Names that are undetected are <em>not</em> randomly distributed through the data but are dispropotionately non-Anglophone. </span></p>
<p>To more clearly see the trends, let’s look at works published under names that we have identified as female across genres; first raw counts and then as a proportion of all works published per year.</p>
<p><img src="/../figs/2015-08-27-gender-in-hathitrust-dataset/htdata-works-by-women-1.png" alt="center" /> <img src="/../figs/2015-08-27-gender-in-hathitrust-dataset/htdata-works-by-women-2.png" alt="center" /></p>
<p>The second graph is the interesting one. Among the genres, female authors are best represented in fiction, and least well-represented in drama. The trend in fiction, however, is odd—while poetry and drama show upward trends (poetry’s is slow and steady across the 19th century; drama’s rather sudden after 1900), fiction has a high point in the early nineteenth century where women represent a larger proportion of fiction writers than anywhere else in this data. At times, early in the data, half of the works of fiction in the dataset are written by a woman (more on this figure below). Yet, over the course of the nineteenth century this proportion diminishes. When the graph ends in 1922, women represent about a quarter of the authors of each of the three genres.</p>
<p><span class="addition"> On twitter, <a href="https://twitter.com/cforster/status/641709866957021185">I suggested</a> that in the normalized data for fiction by women above, one sees a decline in works by women. This may be consistent with the <em>BSPF</em> data (which, in its admittedly narrower slice, shows a decline from 1815 to 1830). To get some sense whether that’s a fair description, let’s isolate the fiction by women data, and add a rolling mean, with a a window of 5.</span></p>
<figure>
<img src="/../figs/2015-08-27-gender-in-hathitrust-dataset/women-and-fiction-with-rolling-mean-1.png" alt="center" /><figcaption aria-hidden="true">center</figcaption>
</figure>
<p><span class="addition">At some point, one is reading Rorschach plots; but this plot seems to suggests two periods of downward trends from 1805–1830, and then again from about 1885 to 1900. (That preciptious drop at the end is a function of doing the rolling average running out of data).</span></p>
<h2 id="data-from-the-english-novel-a-bibliographical-survey-of-prose-fiction-1770-1830">Data from <em>The English Novel: A Bibliographical Survey of Prose Fiction, 1770-1830</em></h2>
<p>To get some sense about how reasonable these trendlines look, we might try to compare them to another source. I’ve already quoted the <em>BSPF</em>, which offers a portrait of the authorship of novels between 1770 and 1830. The <em>BSPF</em> has totals based on both what is stated on title pages and in prefaces, as well as more comprehensive totals based on what the editors were able to infer about the authorship of works from other sources.<span class="marginnote">For instance, if a work states that it is "By the author of <em>Waverley</em>, one can make additional inferences about the author’s gender.</span> There turns out to be a significant discrepancy between what a title page, or preface, states, and what one may be able to infer about the gender of an author with just a little more knowledge. The majority of novels in this period were published without a clear statement of authorship. But if we look at the more comprehensive portrait of authorship that the <em>BSPF</em> offers, the story is a little different.</p>
<figure>
<img src="/../figs/2015-08-27-gender-in-hathitrust-dataset/bspf-data-1.png" alt="center" /><figcaption aria-hidden="true">center</figcaption>
</figure>
<p>The graph above summarizes the trends in the <em>inferred</em> data. It has three distinct moments—a predominance of “anonymous” or unattributed works until around 1800; the predominance of women writers during the first decades of the nineteenth century, and concluding with what Peter Garside calls “the male invasion of mainstream fiction” (2:63). <span class="marginnote">Garside notes, for instance, “the <em>publication</em> of Jane Austen’s novels was achieved not against the grain but during a period of female ascendancy” (2:75).</span> This data suggests that authors of novels were most likely to be, in this order, <em>anonymous</em>, <em>women</em>, and then <em>men</em>.</p>
<p>The three waves visible in the graph above, however, is based on the inferences that the editors of the <em>BSPF</em> made to ascertain the the gender of the authors in their bibliography. The metadata available on title pages—of the sort that’s compiled in the HT metadata—often lacks information that might otherwise be available to most readers.</p>
<blockquote>
<p>Occasionally, full author names are found within a novel—as in a signed Preface, or through the inclusion of an engraved portrait or additional title-page—when the main title-page offers no direct authorial description. Augusta Ann Hirst’s <em>Helen; or Domestic Occurences</em> (1807:28), for example, carries only the bare title on its title-page, though the full author’s name appears immediately afterwards in a Dedication to the Countess Fitzwilliam, and the author’s name later featured directly on the title-page in the Minerva reissue of 1808. (2:68)</p>
</blockquote>
<p>HathiTrust has <a href="http://catalog.hathitrust.org/Record/100004286/Home">a copy of <em>Helen, or, Domestic Occurrences: A Tale</em></a> (though it is not included in the fiction dataset). And indeed its title page lacks the author’s name, though one can discover it in the dedication.</p>
<figure>
<img src="/images/helen_pages.png" alt="Title Page, and End of Dedication from Helen" /><figcaption aria-hidden="true">Title Page, and End of Dedication from <em>Helen</em></figcaption>
</figure>
<p>Through the magic of librarians, the <a href="http://catalog.hathitrust.org/Record/100004286">HathiTrust record</a>, however, includes the correct author and even notes that its “Dedication signed.”</p>
<p>Looking only at what one can infer about the authorial gender of works from the information available on the title page, most works would be “anonymous,” even if (some) contemporary readers may have been able to see through that that anonymity. Note the difference between the trends in authorship when we look only at information available from examining “proper names from title-pages and prefaces only” with the inferred conclusion (all this data is taken from the wonderfully comprehensive <em>BSPF</em>).</p>
<figure>
<img src="/../figs/2015-08-27-gender-in-hathitrust-dataset/bspf-data-2-1.png" alt="center" /><figcaption aria-hidden="true">center</figcaption>
</figure>
<p>The inferred trends for both male and female authorship are significantly higher than their stated counterparts (these terms, <em>inferred</em> and <em>stated</em> are my clumsy language; for anyone interested, <em>The English Novel, 1770–1830</em> really is an invaluable, if imposingly weighty, resource). There are perhaps two interesting trends here. The decrease in anonymous authorship at the start of the nineteenth century coincides with a rise in female authorship; female authorship is <em>more public</em> than its male counterpart. After 1820 one sees a sharp rise in male authorship—which is itself a rise in <em>anonymous</em> male authorship.</p>
<h2 id="comparing-hathitrust-and-bspf">Comparing HathiTrust and <em>BSPF</em></h2>
<p>Using the method described above to infer authorship in the HathiTrust dataset should produce results similar to the raw, stated dates in the <em>BSPF</em> data. There are, though, a few differences to account for first. For one, James Raven’s and Peter Garside’s introductions to the two volumes of the <em>Bibliographical Survey of Prose Fiction</em> offer summary counts of “New Novels” but the HathiTrust data represents <em>books</em> owned by libraries. To be able to compare to the <em>BSPF</em> data with the HT data, we need to eliminate reprints (we only want <em>new</em> novels) and we need to count works, not books (so, multivolume works should be counted as a single work). I’ve tried to do this rather crudely by creating for each work in the HT fiction dataset an “ID” which consists only of a work’s title and it’s author.<span class="marginnote">Using title alone as an ID could, in theory, lead to a problem if two works have the same title—which is actually quite common for multivolume sets, like <em>The Novels</em> of Walter Scott and the <em>The Novels</em> of Charles Dickens, and similar</span> My script loops over the works in the metadata summary, counting a work as “new” only if we haven’t seen its ID before. Because we look only at title and author (and not <code>enumcron</code>), we also only count one volume from a multivolume work (though, as I mention above, this problem is quite a bit thornier than I’m allowing here).</p>
<p>Second complication: <strong>geography</strong>: the HT dataset is culled from American libraries, whereas the <em>BSPF</em> data is focused on works published in “the British Isles.” Well, that raises an interesting question (digression ahead!): where were fiction volumes in the HathiTrust dataset published?</p>
<figure>
<img src="/../figs/2015-08-27-gender-in-hathitrust-dataset/ht-places-of-publication-1.png" alt="center" /><figcaption aria-hidden="true">center</figcaption>
</figure>
<p>As this graph makes clear, most of the works in the HathiTrust dataset were published in 5 places (heck, many were published in <em>one</em> place). Those labels along the x-axis are <a href="http://www.loc.gov/marc/countries/countries_code.html">MARC country codes</a>; so the top publication locations are: New York State (<code>nyu</code>), England (<code>enk</code>), Massachusetts (<code>mau</code>), No place/Unknown (<code>xx</code>), Pennsylvania (<code>pau</code>), Illinois (<code>ilu</code>), Scotland (<code>stk</code>), Germany(<code>gw</code>). This summary, however, represents the entire HT fiction dataset—from 1700-1922. Let’s look at just the portion covered by the <em>BSPF</em>, 1770 and 1830:</p>
<p><img src="/../figs/2015-08-27-gender-in-hathitrust-dataset/ht-places-of-publication-1770-1830-1.png" alt="center" /> For this period the top two locations are England and Scotland. It seems unlikely, therefore, that any differences between the <em>BSPF</em> and the HT datasets could be attributed to the different geographical coverage of the two datasets. But, just to be sure let’s extract only the works from the fiction dataset published in England and Scotland and Ireland between 1770 and 1830, and compare the gender breakdown one last time.</p>
<p>To create this subset of the HT summary metadata, I’ve used some Python that tries to more closely match the parameters of the <em>BSPF</em> data: it covers only works published between 1770 and 1830, published in England, Scotland, or Ireland, and it tries represent only “new works.” <span class="marginnote">The Python that did this is <a href="https://gist.github.com/c-forster/caf3389c74fddffdfcd3">here</a>; the summary of the data is <a href="https://gist.github.com/c-forster/cb23a1224eadfe282257">here</a>.</span></p>
<figure>
<img src="/../figs/2015-08-27-gender-in-hathitrust-dataset/compare-bspf-ht-1.png" alt="center" /><figcaption aria-hidden="true">center</figcaption>
</figure>
<p>We can get some sense of how the HT data compares to <em>BSPF</em> by plotting them together.</p>
<figure>
<img src="/../figs/2015-08-27-gender-in-hathitrust-dataset/dataset-comparisons-1.png" alt="center" /><figcaption aria-hidden="true">center</figcaption>
</figure>
<p>The data for female authorship in the two datasets (or rather, in the <em>BSPF</em> data and my weird manipulation of the HathiTrust data) seems, to my layman’s eye, surprisingly consistent. Of course, recalling the difference (often of between 10 and 20 percentage point) between authorial gender as determined by consulting title pages/prefaces with what the <em>BSPF</em> editors were able to infer, one might suggest (at least for the period 1770–1830) that the summary I offered above significantly under represents female authorship.</p>
<p>The data for male and anonymous authorship is much less consistent; <em>BSPF</em> reports more anonymous texts and my analysis of the HT metadata; while the HT data reports more male writers. I basically don’t understand why this would be so—I would have expected, if anything, the opposite. The <code>anonymous</code> line for the HT data in the above graph combines both <code>missing</code> authors and <code>undetected</code>, treating as anonymous anything that couldn’t be coaxed into another category; if anything, it should <em>overrepresent</em> anonymous writers. Perhaps this reflects something about the underlying data; or perhaps something about the way I carved up first names. For now, I just don’t know. So, here ends our amble through the data.</p>
<h2 id="works-cited">Works Cited</h2>
<p>Woolf, Virginia. <em>A Room of One’s Own</em>.</p>
<p>Raven, James et al. <em>The English Novel 1770-1829: A Bibliographical Survey of Prose Fiction Published in the British Isles</em>. 2 vols. New York: Oxford University Press, 2000. Print.</p>

      </div>
      <div id="disqus_thread"></div>
      <script type="text/javascript"
	      src="http://disqus.com/forums/chrisforstersblog/embed.js">
      </script>
      <noscript>
	<a href="http://chrisforstersblog.disqus.com/?url=ref">View the discussion thread.</a>
      </noscript>
      <a href="http://disqus.com" class="dsq-brlink">
	blog comments powered by <span class="logo-disqus">Disqus</span>
      </a>
    </article>
  </body>

</html>
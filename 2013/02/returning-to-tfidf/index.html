<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Chris Forster: (de)Bugging Ramsay—A Last Stab at tfidf and “The Waves”
</title>
    <meta charset="UTF-8">

    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" type="text/css" href="/css/pygments.css" />
    <link rel="stylesheet" type="text/css" href="/css/style.css" />
    <link href="/atom.xml" type="application/atom+xml" rel="alternate" title="cforster.com Atom feed" />
  </head>
  <body>

    <article class="post">
      <div class="frontmatter">
	<h1 class="title"><p>(de)Bugging Ramsay—A Last Stab at tfidf and “The Waves”</p>
</h1>

	<time class="timestamp" datetime="2013-02-26" >Feb 26, 2013</time>
      </div>

      <div class="post-content">
	<p>In my <a href="http://cforster.com/2013/02/reading-the-waves-with-stephen-ramsay/">last post</a> I talked about some of the challenges of reproducing the analysis, offered in Stephen Ramsay’s <em>Reading Machines</em> of the distinctiveness of characters’ vocabulary in Woolf’s <em>The Waves</em>. Here I follow up a bit more on why I was unable to get the same results Ramsay reports.</p>
<h1 id="r-tm-and-weighttfidf"><code>R</code>, <code>tm</code>, and <code>weightTfIdf</code></h1>
<p>To get <code>R</code> to generate tf—idf scores, one can do the following:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate a Document Term Matrix</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>dtm <span class="ot">&lt;-</span> <span class="fu">DocumentTermMatrix</span>(corpus, <span class="at">control=</span><span class="fu">list</span>(<span class="at">weighting=</span>weightTfIdf))</span></code></pre></div>
<p>This was how I got my scores last time; and those scores didn’t match the one’s reported by Ramsay. So, one explanation is that I bollocks’d the data; the other is that there may be something going on under the hood.</p>
<p>To explore this latter possibility, I had a look at the <code>weightTfIdf</code> function.<span class="marginnote">Doing so is easy; if you’re in an <code>R</code> console, with the <code>tm</code> package loaded, just type <code>weightTfIdf</code> and you’ll get all 26 lines of the code.</span> It is worth noting that by default, the function normalizes its scores according to text. That is, rather than calculating the tf-idf score using a raw count of the number of times a particular term appears in a single document (in our case, the number of times a particular character uses a word), it divides the raw term frequency by the total number of words in that document (in our case, the total number of words said by a character). This normalizing process explains why the scores Ramsay reports for Louis (12) start at 5.9, while my own scores were always small numbers (0.006…; 0.003…, etc).</p>
<h2 id="short-digression-on-misunderstanding-the-code">Short digression on misunderstanding the code</h2>
<p>When I first dug into <code>weightTfIdf</code> code, I thought I discovered a difference in implementation:<span class="marginnote">In order to work with the data, this function transposes the Document Term Matrix into a Term Document Matrix; this means that rather than the columns being terms and the rows texts, the rows are terms and the columns documents. I don’t know <em>why</em> the function does this; but it does, and that explains why we’re looking at row sums in what follows rather than column sums.</span></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>lnrs <span class="ot">&lt;-</span> <span class="fu">log2</span>(<span class="fu">nDocs</span>(m)<span class="sc">/</span>rs)</span></code></pre></div>
<p>Here we’re calculating part of the <em>tf-idf</em> score—the part that corresponds to Ramsay’s log(N/df). Ignore the <code>log2</code> for a moment and look at that divisor, <code>rs</code>. That should represent the number of documents which contain a particular term. How is that calculated? Well, the code says:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>rs <span class="ot">&lt;-</span> <span class="fu">row_sums</span>(m <span class="sc">&gt;</span> <span class="dv">0</span>)</span></code></pre></div>
<p>That <code>row_sums</code> function comes the <code>slam</code> package; and when I first saw this, I thought I had my explanation. Ah ha! If the divisor in the logarithm is the sum of a row, then it is dividing the number of documents <em>not</em> by the number of documents which contain the specified term, but by the sum of the row—that is, by the total occurrences of that term! Here is our explanation!</p>
<p>“Well, but what is that comparison, <code>m &gt; 0</code>, doing in the function call,” you ask? Good question! Well, I assumed that it was just a way to pass non-zero values to the <code>row_sums</code> function, and went about trying to rewrite the function properly. This heady delirium lead to <a href="http://stackoverflow.com/questions/15045313/changing-tf-idf-weight-function-weight-not-by-occurrences-of-term-but-by-numbe">questions</a> on StackOverflow and wasted time. Because, of course, I totally misunderstood how this part of the code works.</p>
<p>The trick is that a relational operator (like <code>&gt;</code>) on a matrix, returns a matrix with boolean values, evaluating that expression for each item in the matrix. So, each cell in the term document matrix is now either <code>TRUE</code> or <code>FALSE</code> based on whether the value of that term was greater than 0. So it might look something like this:</p>
<pre><code>             Docs
Terms         bernard.txt jinny.txt louis.txt neville.txt rhoda.txt susan.txt
  absorption         TRUE     FALSE     FALSE       FALSE     FALSE     FALSE
  abstract           TRUE     FALSE     FALSE       FALSE     FALSE     FALSE
  abstraction       FALSE     FALSE      TRUE       FALSE     FALSE     FALSE
  absurd             TRUE     FALSE     FALSE        TRUE     FALSE     FALSE
  absurdity          TRUE     FALSE     FALSE        TRUE     FALSE     FALSE
  absurdly          FALSE     FALSE     FALSE        TRUE     FALSE     FALSE</code></pre>
<p>And, since TRUE is treated as numerically equivalent to 1, and FALSE to 0, if we were to sum these rows, we would get… exactly what we were looking for; i.e., the number of documents in which the term appears. So, that was wasted time.</p>
<p>Another thing to note here is that <code>weightTfIdf</code> uses <code>log2()</code>, the binary logarithm<span class="marginnote">Which returns the exponent to which you would raise 2 in order to get the specified term; i.e. log2(16)=4, b/c 2^4=16.</span>. The logarithm here works to essentially scale the term’s frequency based on how specific the term is to any particular document; terms which occur in all documents will have <code>N</code> nearly equal to <code>df</code>, or <code>N/df</code> nearly equal to 1. And <code>log(1) == log2(1) == 0</code>. That is, it will push the weight to (or towards) 0. Whereas a term which occurs in only one document will maximize <code>N/1</code>. A logarithmic function is used simply to dampen that effect, preventing scores linearly increasing in the case of terms highly specific to a single document.</p>
<p>Does it make a difference whether one uses <code>log2()</code> or the natural logarithm or the base 10 “common” logarithm I learned back in school? I don’t really know; I doubt it. The particular logarithmic function one chooses will change the <em>score</em>, but it wouldn’t change the relationship among the terms (which had the <em>highest</em> score).</p>
<h2 id="hand-simulations">Hand Simulations</h2>
<p>After all that, I tried to tinker a bit to bring results into line. I stopped normalizing my data and tried different log functions in an attempt to match Ramsay’s scores. Well, okay, let’s take one last look.</p>
<p>Despairing, I returned to the clearest data Ramsay gives us—the list of terms and scores which appears on page 12 and picked a few, to see if I could manage this by hand.<span class="marginnote">My high school computer science teacher (we switched from Pascal to C++ midway through my high school career) used to make us “hand simulate” algorithms; print out the source code, jot down the variable names, and debug by hand. Smart guy. (Though the phrase “hand simulation” may have been unfortunate.)</span> (I don’t <em>really</em> mean by hand of course. Just… more slowly.) Here are the terms Ramsay lists for Louis, which have a score of 5.0021615: australian, beast, grained, though, wilt.</p>
<p>So, I returned to my data.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> rawdtm <span class="ot">&lt;-</span> <span class="fu">DocumentTermMatrix</span>(characters)  <span class="co"># A basic Document Term Matrix of raw frequency counts</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> terms <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;australian&#39;</span>,<span class="st">&#39;beast&#39;</span>,<span class="st">&#39;grained&#39;</span>,<span class="st">&#39;thou&#39;</span>,<span class="st">&#39;wilt&#39;</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">inspect</span>(rawdtm[,terms])</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  A document<span class="sc">-</span>term <span class="fu">matrix</span> (<span class="dv">6</span> documents, <span class="dv">5</span> terms)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    Non<span class="sc">-</span><span class="er">/</span>sparse entries<span class="sc">:</span> <span class="dv">6</span><span class="sc">/</span><span class="dv">24</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    Sparsity           <span class="sc">:</span> <span class="dv">80</span>%</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    Maximal term length<span class="sc">:</span> <span class="dv">10</span> </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    Weighting          <span class="sc">:</span> term <span class="fu">frequency</span> (tf)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>                 Terms</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    Docs          australian beast grained thou wilt</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>      bernard.txt          <span class="dv">1</span>     <span class="dv">0</span>       <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>      jinny.txt            <span class="dv">0</span>     <span class="dv">0</span>       <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>      louis.txt            <span class="dv">6</span>     <span class="dv">6</span>       <span class="dv">6</span>    <span class="dv">6</span>    <span class="dv">6</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>      neville.txt          <span class="dv">0</span>     <span class="dv">0</span>       <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>      rhoda.txt            <span class="dv">0</span>     <span class="dv">0</span>       <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>      susan.txt            <span class="dv">0</span>     <span class="dv">0</span>       <span class="dv">0</span>    <span class="dv">0</span>    <span class="dv">0</span></span></code></pre></div>
<p>This is already puzzling. These five terms all had the same score. Yet, <em>australian</em> occurs six times in Louis, but across two texts; while the other terms occurs six time in Louis, and <em>only</em> in Louis.</p>
<p>So, back to the data. I open up the original gutenberg and search through it for australian. And, indeed, looks like 7 total occurrences; one of which is from Bernard:</p>
<blockquote>
<p>I thought how Louis would mount those steps in his neat suit with his cane in his hand and his angular, rather detached gait. With his Australian accent (“My father, a banker at Brisbane”) he would come, I thought, with greater respect to these old ceremonies than I do, who have heard the same lullabies for a thousand years.</p>
</blockquote>
<p>Let’s check <em>grained</em>. I found six occurrences; all in Louis’s speech and, as I was doing this by hand, I noticed that all those occurrences of <em>grained</em> were in the phrase <em>grained oak</em>:</p>
<ul>
<li>“the grained oak panel of Mr Wickham’s door”</li>
<li>“…Mr Wickham’s grained oak door”</li>
<li>“…I am also one who will force himself to desert these windy and moonlit territories, these midnight wanderings, and confront grained oak doors.”</li>
<li>“I, the companion of Plato, of Virgil, will knock at the grained oak door.”</li>
<li>“I brought down my fist on my master’s grained oak door.”</li>
<li>“…yet brought down my fist on the grained oak door”</li>
</ul>
<p>Why does <em>grained</em> occur in Ramsay &amp; Steger’s list, but not <em>oak</em>? Well, maybe <em>everyone</em> talks about oak trees, but only Louis talks about <em>grained oak</em>. Back to our data:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span><span class="fu">inspect</span>(rawdtm[,<span class="fu">c</span>(<span class="st">&#39;grained&#39;</span>,<span class="st">&#39;oak&#39;</span>)])</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>A document<span class="sc">-</span>term <span class="fu">matrix</span> (<span class="dv">6</span> documents, <span class="dv">2</span> terms)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>Non<span class="sc">-</span><span class="er">/</span>sparse entries<span class="sc">:</span> <span class="dv">3</span><span class="sc">/</span><span class="dv">9</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>Sparsity           <span class="sc">:</span> <span class="dv">75</span>%</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>Maximal term length<span class="sc">:</span> <span class="dv">7</span> </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>Weighting          <span class="sc">:</span> term <span class="fu">frequency</span> (tf)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>                 Terms</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>Docs          grained oak</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>bernard.txt       <span class="dv">0</span>   <span class="dv">2</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>jinny.txt         <span class="dv">0</span>   <span class="dv">0</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>louis.txt         <span class="dv">6</span>  <span class="dv">10</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>neville.txt       <span class="dv">0</span>   <span class="dv">0</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>rhoda.txt         <span class="dv">0</span>   <span class="dv">0</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>susan.txt         <span class="dv">0</span>   <span class="dv">0</span></span></code></pre></div>
<p>Hmm… well, let’s do the math for these three terms (the first two of which got the same score in Ramsay’s analysis; the last of which didn’t appear at all). For these three terms, <em>australian</em>, <em>oak</em>, and <em>grained</em> for Louis, we have:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>             tf    df    N    <span class="dv">1</span><span class="sc">+</span>tf<span class="sc">*</span>(<span class="fu">log2</span>(N<span class="sc">/</span>df))   <span class="dv">1</span><span class="sc">+</span>tf<span class="sc">*</span>(<span class="fu">log10</span>(N<span class="sc">/</span>df))    <span class="dv">1</span><span class="sc">+</span>tf<span class="sc">*</span>(<span class="fu">log</span>(N<span class="sc">/</span>df))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>australian    <span class="dv">6</span>     <span class="dv">2</span>    <span class="dv">6</span>         <span class="fl">10.50978</span>          <span class="fl">3.862728</span>               <span class="fl">7.59164</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>grained       <span class="dv">6</span>     <span class="dv">1</span>    <span class="dv">6</span>         <span class="fl">16.50978</span>          <span class="fl">5.668909</span>              <span class="fl">11.75056</span> </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>oak           <span class="dv">10</span>    <span class="dv">2</span>    <span class="dv">6</span>         <span class="fl">16.84963</span>          <span class="fl">5.771213</span>              <span class="fl">11.98612</span></span></code></pre></div>
<p>So oak should have the <em>highest</em> score of the three.</p>
<p>Something is clearly wrong.</p>
<p>I’ve returned to the raw counts, double checked them against the original file; and computed these things individually. I’ve tried to imagine all possible ways, but have been unable to produce any of the scores listed on pg 12.</p>
<p>I suspect that there may be a problem in the Ramsay and Steger’s data. There is significant overlap in Ramsay and Steger’s results and my own. It is for Louis that our data is <em>most</em> consistent; we share 19 of the top 24 terms. It is least similar for Bernard (sharing only <em>4/24</em> terms) and Rhoda (11/24). Did the Ramsay &amp; Steger’s analysis, perhaps, discard the final chapter where only Bernard talks (perhaps deliberately)? That would obviously <em>greatly</em> change the Bernard data set; and, by removing so much text, it could easily affect the <em>df</em> term for other characters, accounting for the other discrepancies. (But it wouldn’t explain <em>oak</em>.)</p>
<p>It may very well be <em>my</em> data that is the problem, but if so I’ve been unable to locate the error. I’m abandoning trying to reconcile these approaches to a method that <em>should</em>, in principle, be eminently reproducible. I will though summarize the top 24 terms with highest tf-idf scores, using the best data I’ve got, and not normalizing.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>    <span class="sc">&gt;</span> louis[<span class="dv">1</span><span class="sc">:</span><span class="dv">24</span>]</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>       western        oak      beast    grained       thou       wilt     accent </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>     <span class="fl">23.264663</span>  <span class="fl">15.849625</span>  <span class="fl">15.509775</span>  <span class="fl">15.509775</span>  <span class="fl">15.509775</span>  <span class="fl">15.509775</span>  <span class="fl">14.000000</span> </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>      boasting       nile    average     clerks     stamps australian       boys </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>     <span class="fl">12.679700</span>  <span class="fl">12.679700</span>  <span class="fl">10.339850</span>  <span class="fl">10.339850</span>  <span class="fl">10.000000</span>   <span class="fl">9.509775</span>   <span class="fl">8.000000</span> </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>      pitchers      steel     beaten      boast    bobbing    custard eatingshop </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>      <span class="fl">7.924813</span>   <span class="fl">7.924813</span>   <span class="fl">7.754888</span>   <span class="fl">7.754888</span>   <span class="fl">7.754888</span>   <span class="fl">7.754888</span>   <span class="fl">7.754888</span> </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>       england      eyres        ham </span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>      <span class="fl">7.754888</span>   <span class="fl">7.754888</span>   <span class="fl">7.754888</span> </span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    <span class="sc">&gt;</span> bernard[<span class="dv">1</span><span class="sc">:</span><span class="dv">24</span>]</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    curiosity   hampton    letter   phrases     byron   elderly    heaven   married </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>     <span class="fl">25.84963</span>  <span class="fl">23.77444</span>  <span class="fl">23.26466</span>  <span class="fl">22.22858</span>  <span class="fl">22.18948</span>  <span class="fl">20.67970</span>  <span class="fl">20.67970</span>  <span class="fl">20.67970</span> </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>     observed    dinner    phrase    willow       fin    simple  describe      self </span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>     <span class="fl">20.67970</span>  <span class="fl">20.60451</span>  <span class="fl">20.00000</span>  <span class="fl">19.01955</span>  <span class="fl">18.09474</span>  <span class="fl">18.09474</span>  <span class="fl">17.43459</span>  <span class="fl">17.43459</span> </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        stick     sense     story    nature  pictures  thinking    canopy     enemy </span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>     <span class="fl">17.43459</span>  <span class="fl">16.37895</span>  <span class="fl">16.00000</span>  <span class="fl">15.84963</span>  <span class="fl">15.84963</span>  <span class="fl">15.84963</span>  <span class="fl">15.50978</span>  <span class="fl">15.50978</span> </span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    <span class="sc">&gt;</span> neville[<span class="dv">1</span><span class="sc">:</span><span class="dv">24</span>]</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>          story      doomed immitigable      papers       byron    catullus </span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>      <span class="fl">12.000000</span>   <span class="fl">10.339850</span>   <span class="fl">10.339850</span>   <span class="fl">10.339850</span>    <span class="fl">7.924813</span>    <span class="fl">7.924813</span> </span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>          cheep  perfection       camel      detect         don   hosepipes </span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>       <span class="fl">7.924813</span>    <span class="fl">7.924813</span>    <span class="fl">7.754888</span>    <span class="fl">7.754888</span>    <span class="fl">7.754888</span>    <span class="fl">7.754888</span> </span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>         hubbub       loads      mallet      marvel   squirting       waits </span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>       <span class="fl">7.754888</span>    <span class="fl">7.754888</span>    <span class="fl">7.754888</span>    <span class="fl">7.754888</span>    <span class="fl">7.754888</span>    <span class="fl">7.754888</span> </span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>           boys     founder      knives      pocket       scene shakespeare </span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>       <span class="fl">7.000000</span>    <span class="fl">6.339850</span>    <span class="fl">6.339850</span>    <span class="fl">6.339850</span>    <span class="fl">6.339850</span>    <span class="fl">6.339850</span> </span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    <span class="sc">&gt;</span> jinny[<span class="dv">1</span><span class="sc">:</span><span class="dv">24</span>]</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        tunnel   prepared  billowing       game     native      peers    quicker </span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>      <span class="fl">9.509775</span>   <span class="fl">7.924813</span>   <span class="fl">7.754888</span>   <span class="fl">7.754888</span>   <span class="fl">7.754888</span>   <span class="fl">7.754888</span>   <span class="fl">7.754888</span> </span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>    melancholy     bodies       band    cabinet      coach       crag     dazzle </span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>      <span class="fl">6.339850</span>   <span class="fl">5.264663</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span> </span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>        deftly   equipped   eyebrows     felled  haymarket       jump    lockets </span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>      <span class="fl">5.169925</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span> </span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>      matthews   murmured    prepare </span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>      <span class="fl">5.169925</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span> </span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>    <span class="sc">&gt;</span> rhoda[<span class="dv">1</span><span class="sc">:</span><span class="dv">24</span>]</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>       oblong      dips     tiger    fuller   swallow    fallen     steep suspended </span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>    <span class="fl">18.094738</span> <span class="fl">12.924813</span> <span class="fl">11.094738</span> <span class="fl">10.339850</span>  <span class="fl">9.509775</span>  <span class="fl">8.000000</span>  <span class="fl">7.924813</span>  <span class="fl">7.924813</span> </span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>       cliffs   minnows      pond    terror     bunch      foam     party    puddle </span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>     <span class="fl">7.754888</span>  <span class="fl">7.754888</span>  <span class="fl">7.754888</span>  <span class="fl">7.000000</span>  <span class="fl">6.339850</span>  <span class="fl">6.339850</span>  <span class="fl">6.339850</span>  <span class="fl">6.339850</span> </span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>        pools   violets       bow   caverns     chirp     choke    column   columns </span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>     <span class="fl">6.000000</span>  <span class="fl">6.000000</span>  <span class="fl">5.169925</span>  <span class="fl">5.169925</span>  <span class="fl">5.169925</span>  <span class="fl">5.169925</span>  <span class="fl">5.169925</span>  <span class="fl">5.169925</span> </span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    <span class="sc">&gt;</span> susan[<span class="dv">1</span><span class="sc">:</span><span class="dv">24</span>]</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>       kitchen     setter    washing       bury       cart       gate      apron </span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>     <span class="fl">15.849625</span>  <span class="fl">10.339850</span>  <span class="fl">10.339850</span>   <span class="fl">8.000000</span>   <span class="fl">7.924813</span>   <span class="fl">7.924813</span>   <span class="fl">7.754888</span> </span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>       seasons   squirrel windowpane       beds     butter      clean        wet </span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>      <span class="fl">7.754888</span>   <span class="fl">7.754888</span>   <span class="fl">7.754888</span>   <span class="fl">6.339850</span>   <span class="fl">6.339850</span>   <span class="fl">6.339850</span>   <span class="fl">6.339850</span> </span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>         blown     winter       baby     bitten       boil   cabbages   carbolic </span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>      <span class="fl">6.000000</span>   <span class="fl">5.264663</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span> </span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>         clara     cradle       eggs </span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>      <span class="fl">5.169925</span>   <span class="fl">5.169925</span>   <span class="fl">5.169925</span> </span></code></pre></div>

      </div>
      <div id="disqus_thread"></div>
      <script type="text/javascript"
	      src="http://disqus.com/forums/chrisforstersblog/embed.js">
      </script>
      <noscript>
	<a href="http://chrisforstersblog.disqus.com/?url=ref">View the discussion thread.</a>
      </noscript>
      <a href="http://disqus.com" class="dsq-brlink">
	blog comments powered by <span class="logo-disqus">Disqus</span>
      </a>
    </article>
  </body>

</html>